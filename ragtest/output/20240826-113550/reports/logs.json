{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197927, Requested 4096. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197927, Requested 4096. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198094, Requested 4096. Please try again in 657ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198094, Requested 4096. Please try again in 657ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196746, Requested 4096. Please try again in 252ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196746, Requested 4096. Please try again in 252ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198834, Requested 4096. Please try again in 879ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198834, Requested 4096. Please try again in 879ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198608, Requested 4096. Please try again in 811ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198608, Requested 4096. Please try again in 811ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198908, Requested 4096. Please try again in 901ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198908, Requested 4096. Please try again in 901ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197606, Requested 4096. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197606, Requested 4096. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197236, Requested 4096. Please try again in 399ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197236, Requested 4096. Please try again in 399ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196659, Requested 4096. Please try again in 226ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196659, Requested 4096. Please try again in 226ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196335, Requested 4096. Please try again in 129ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196335, Requested 4096. Please try again in 129ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196625, Requested 4096. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196625, Requested 4096. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199040, Requested 4096. Please try again in 940ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199040, Requested 4096. Please try again in 940ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197608, Requested 4096. Please try again in 511ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197608, Requested 4096. Please try again in 511ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196082, Requested 4096. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196082, Requested 4096. Please try again in 53ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199729, Requested 4096. Please try again in 1.147s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199729, Requested 4096. Please try again in 1.147s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199084, Requested 4096. Please try again in 954ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199084, Requested 4096. Please try again in 954ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197478, Requested 4096. Please try again in 472ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197478, Requested 4096. Please try again in 472ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196832, Requested 4096. Please try again in 278ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196832, Requested 4096. Please try again in 278ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198907, Requested 4096. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198907, Requested 4096. Please try again in 900ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197986, Requested 4096. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197986, Requested 4096. Please try again in 624ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197163, Requested 4096. Please try again in 377ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197163, Requested 4096. Please try again in 377ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196613, Requested 4096. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196613, Requested 4096. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196583, Requested 4096. Please try again in 203ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196583, Requested 4096. Please try again in 203ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198865, Requested 4096. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198865, Requested 4096. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196919, Requested 4096. Please try again in 304ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196919, Requested 4096. Please try again in 304ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195944, Requested 4096. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195944, Requested 4096. Please try again in 12ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199143, Requested 4096. Please try again in 971ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199143, Requested 4096. Please try again in 971ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197713, Requested 4096. Please try again in 542ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197713, Requested 4096. Please try again in 542ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197748, Requested 4096. Please try again in 553ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197748, Requested 4096. Please try again in 553ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
