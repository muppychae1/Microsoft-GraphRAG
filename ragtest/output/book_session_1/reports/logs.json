{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197318, Requested 4096. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197318, Requested 4096. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199591, Requested 4096. Please try again in 1.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199591, Requested 4096. Please try again in 1.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196100, Requested 4096. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196100, Requested 4096. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196315, Requested 4096. Please try again in 123ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196315, Requested 4096. Please try again in 123ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198339, Requested 4096. Please try again in 730ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198339, Requested 4096. Please try again in 730ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198003, Requested 4096. Please try again in 629ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198003, Requested 4096. Please try again in 629ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196685, Requested 4096. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196685, Requested 4096. Please try again in 234ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196676, Requested 4096. Please try again in 231ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196676, Requested 4096. Please try again in 231ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196414, Requested 4096. Please try again in 153ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196414, Requested 4096. Please try again in 153ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195926, Requested 4096. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195926, Requested 4096. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198898, Requested 4096. Please try again in 898ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198898, Requested 4096. Please try again in 898ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198230, Requested 4096. Please try again in 697ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198230, Requested 4096. Please try again in 697ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197287, Requested 4096. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197287, Requested 4096. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197635, Requested 4096. Please try again in 519ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197635, Requested 4096. Please try again in 519ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196765, Requested 4096. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196765, Requested 4096. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196047, Requested 4096. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196047, Requested 4096. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197239, Requested 4096. Please try again in 400ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197239, Requested 4096. Please try again in 400ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197478, Requested 4096. Please try again in 472ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197478, Requested 4096. Please try again in 472ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197215, Requested 4096. Please try again in 393ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197215, Requested 4096. Please try again in 393ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196463, Requested 4096. Please try again in 167ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196463, Requested 4096. Please try again in 167ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198947, Requested 4096. Please try again in 912ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198947, Requested 4096. Please try again in 912ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197525, Requested 4096. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197525, Requested 4096. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196476, Requested 4096. Please try again in 171ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196476, Requested 4096. Please try again in 171ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197833, Requested 4096. Please try again in 578ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197833, Requested 4096. Please try again in 578ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198844, Requested 4096. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198844, Requested 4096. Please try again in 882ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198708, Requested 4096. Please try again in 841ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198708, Requested 4096. Please try again in 841ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198314, Requested 4096. Please try again in 723ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198314, Requested 4096. Please try again in 723ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197420, Requested 4096. Please try again in 454ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197420, Requested 4096. Please try again in 454ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197394, Requested 4096. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197394, Requested 4096. Please try again in 447ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197170, Requested 4096. Please try again in 379ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197170, Requested 4096. Please try again in 379ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197179, Requested 4096. Please try again in 382ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197179, Requested 4096. Please try again in 382ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196044, Requested 4096. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196044, Requested 4096. Please try again in 42ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195961, Requested 4096. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195961, Requested 4096. Please try again in 17ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197576, Requested 4096. Please try again in 501ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197576, Requested 4096. Please try again in 501ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196738, Requested 4096. Please try again in 250ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196738, Requested 4096. Please try again in 250ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_transports\\default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_transports\\default.py\", line 373, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 216, in handle_async_request\n    raise exc from None\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 196, in handle_async_request\n    response = await connection.handle_async_request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n    return await self._connection.handle_async_request(request)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 143, in handle_async_request\n    raise exc\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 113, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 186, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 224, in _receive_event\n    data = await self._network_stream.read(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 32, in read\n    with map_exceptions(exc_map):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1548, in _request\n    response = await self._client.send(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_client.py\", line 1661, in send\n    response = await self._send_handling_auth(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_client.py\", line 1689, in _send_handling_auth\n    response = await self._send_handling_redirects(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_client.py\", line 1726, in _send_handling_redirects\n    response = await self._send_single_request(request)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_client.py\", line 1763, in _send_single_request\n    response = await transport.handle_async_request(request)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_transports\\default.py\", line 372, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_transports\\default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1567, in _request\n    raise APITimeoutError(request=request) from err\nopenai.APITimeoutError: Request timed out.\n", "source": "Request timed out.", "details": {"input": "\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity's attributes and activities\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis's Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n(\"entity\"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n(\"entity\"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n(\"entity\"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis's money supply)\n##\n(\"relationship\"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal's (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation's debut on the public markets isn't indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n(\"entity\"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n(\"entity\"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n(\"relationship\"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad's capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia's capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia's Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n(\"entity\"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n(\"entity\"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n(\"entity\"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n(\"entity\"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n(\"entity\"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n(\"entity\"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n(\"entity\"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia's Alhamia Prison)\n##\n(\"entity\"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n(\"entity\"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n(\"entity\"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n(\"relationship\"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n(\"relationship\"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n(\"relationship\"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n(\"relationship\"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n(\"relationship\"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n(\"relationship\"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n(\"relationship\"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n(\"relationship\"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n(\"relationship\"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n(\"relationship\"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: reports; for Laurie was always playing truant, and running over to the Marches. \"Never mind; let him take a holiday, and make it up afterwards,\" said the old gentleman. \"The good lady next door says he is studying too hard, and needs young society, amusement, and exercise. I suspect she is right, and that I've been coddling the fellow as if I'd been his grandmother. Let him do what he likes, as long as he is happy. He can't get into mischief in that little nunnery over there; and Mrs. March is doing more for him than we can.\" What good times they had, to be sure! Such plays and tableaux, such sleigh-rides and skating frolics, such pleasant evenings in the old parlor, and now and then such gay little parties at the great house. Meg could walk in the conservatory whenever she liked, and revel in bouquets; Jo browsed over the new library voraciously, and convulsed the old gentleman with her criticisms; Amy copied pictures, and enjoyed beauty to her heart's content; and Laurie played \"lord of the manor\" in the most delightful style. But Beth, though yearning for the grand piano, could not pluck up courage to go to the \"Mansion of Bliss,\" as Meg called it. She went once with Jo; but the old gentleman, not being aware of her infirmity, stared at her so hard from under his heavy eyebrows, and said \"Hey!\" so loud, that he frightened her so much her \"feet chattered on the floor,\" she told her mother; and she ran away, declaring she would never go there any more, not even for the dear piano. No persuasions or enticements could overcome her fear, till, the fact coming to Mr. Laurence's ear in some mysterious way, he set about mending matters. During one of the brief calls he made, he artfully led the conversation to music, and talked away about great singers whom he had seen, fine organs he had heard, and told such charming anecdotes that Beth found it impossible to stay in her distant corner, but crept nearer and nearer, as if fascinated. At the back of his chair she stopped, and stood listening, with her great eyes wide open, and her cheeks red with the excitement of this unusual performance. Taking no more notice of her than if she had been a fly, Mr. Laurence talked on about Laurie's lessons and teachers; and presently, as if the idea had just occurred to him, he said to Mrs. March,-- \"The boy neglects his music now, and I'm glad of it, for he was getting too fond of it. But the piano suffers for want of use. Wouldn't some of your girls like to run over, and practise on it now and then, just to keep it in tune, you know, ma'am?\" Beth took a step forward, and pressed her hands tightly together to keep from clapping them, for this was an irresistible temptation; and the thought of practising on that splendid instrument quite took her breath away. Before Mrs. March could reply, Mr. Laurence went on with an odd little nod and smile,-- \"They needn't see or speak to any one, but run in at any time; for I'm shut up in my study at the other end of the house, Laurie is out a great deal, and the servants are never near the drawing-room after nine o'clock.\" Here he rose, as if going, and Beth made up her mind to speak, for that last arrangement left nothing to be desired. \"Please tell the young ladies what I say; and if they don't care to come, why, never mind.\" Here a little hand slipped into his, and Beth looked up at him with a face full of gratitude, as she said, in her earnest yet timid way,-- \"O sir, they do care, very, very much!\" [Illustration: O sir, they do care very much] \"Are you the musical girl?\" he asked, without any startling \"Hey!\" as he looked down at her very kindly. \"I'm Beth. I love it dearly, and I'll come, if you are quite sure nobody will hear me--and be disturbed,\" she added, fearing to be rude, and trembling at her own boldness as she spoke. \"Not a soul, my dear. The house is empty half the day; so come, and drum away as much as you like, and I shall be obliged to you.\" \"How kind you are, sir!\" Beth blushed like a rose under the friendly look he wore; but she was not frightened now, and gave the big hand a grateful squeeze, because she had no words to thank him for the precious gift he had given her. The old gentleman softly stroked the hair off her forehead, and, stooping down, he kissed her, saying, in a tone few people ever heard,-- \"I had a little girl once, with eyes like these. God bless you, my dear! Good day, madam;\" and away he went, in a great hurry. Beth had a rapture with her mother, and then rushed up to impart the glorious news to her family of invalids, as the girls were not at home. How blithely she sung that evening, and how they all laughed at her, because she woke Amy in the night by playing the piano on her face in her sleep. Next day, having seen both the old and young gentleman out of the house, Beth, after two or three retreats, fairly got in at the side-door, and made her way, as noiselessly as any mouse, to the drawing-room, where her idol stood. Quite by accident, of course, some pretty, easy music\n######################\nOutput:"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197152, Requested 4096. Please try again in 374ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197152, Requested 4096. Please try again in 374ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197095, Requested 4096. Please try again in 357ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197095, Requested 4096. Please try again in 357ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197344, Requested 4096. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197344, Requested 4096. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195931, Requested 4096. Please try again in 8ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195931, Requested 4096. Please try again in 8ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197212, Requested 4096. Please try again in 392ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197212, Requested 4096. Please try again in 392ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198591, Requested 4096. Please try again in 806ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198591, Requested 4096. Please try again in 806ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196199, Requested 4096. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196199, Requested 4096. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196061, Requested 4096. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196061, Requested 4096. Please try again in 47ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197420, Requested 4096. Please try again in 454ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197420, Requested 4096. Please try again in 454ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196869, Requested 4096. Please try again in 289ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196869, Requested 4096. Please try again in 289ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198992, Requested 4096. Please try again in 926ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198992, Requested 4096. Please try again in 926ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197094, Requested 4096. Please try again in 357ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197094, Requested 4096. Please try again in 357ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196583, Requested 4096. Please try again in 203ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196583, Requested 4096. Please try again in 203ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196404, Requested 4096. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196404, Requested 4096. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199230, Requested 4096. Please try again in 997ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199230, Requested 4096. Please try again in 997ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199068, Requested 4096. Please try again in 949ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199068, Requested 4096. Please try again in 949ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199235, Requested 4096. Please try again in 999ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199235, Requested 4096. Please try again in 999ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198736, Requested 4096. Please try again in 849ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198736, Requested 4096. Please try again in 849ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198745, Requested 4096. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198745, Requested 4096. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196920, Requested 4096. Please try again in 304ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196920, Requested 4096. Please try again in 304ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197640, Requested 4096. Please try again in 520ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197640, Requested 4096. Please try again in 520ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197229, Requested 4096. Please try again in 397ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197229, Requested 4096. Please try again in 397ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196038, Requested 4096. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196038, Requested 4096. Please try again in 40ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195978, Requested 4096. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195978, Requested 4096. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195926, Requested 4096. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195926, Requested 4096. Please try again in 6ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197276, Requested 4096. Please try again in 411ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197276, Requested 4096. Please try again in 411ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197193, Requested 4096. Please try again in 386ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197193, Requested 4096. Please try again in 386ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199811, Requested 4096. Please try again in 1.172s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199811, Requested 4096. Please try again in 1.172s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199030, Requested 4096. Please try again in 937ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199030, Requested 4096. Please try again in 937ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197978, Requested 4096. Please try again in 622ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197978, Requested 4096. Please try again in 622ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197969, Requested 4096. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197969, Requested 4096. Please try again in 619ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196455, Requested 4096. Please try again in 165ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196455, Requested 4096. Please try again in 165ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195950, Requested 4096. Please try again in 13ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195950, Requested 4096. Please try again in 13ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197648, Requested 4096. Please try again in 523ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197648, Requested 4096. Please try again in 523ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198353, Requested 4096. Please try again in 734ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198353, Requested 4096. Please try again in 734ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197736, Requested 4096. Please try again in 549ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197736, Requested 4096. Please try again in 549ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197715, Requested 4096. Please try again in 543ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197715, Requested 4096. Please try again in 543ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198443, Requested 4096. Please try again in 761ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198443, Requested 4096. Please try again in 761ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198365, Requested 4096. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198365, Requested 4096. Please try again in 738ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197511, Requested 4096. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197511, Requested 4096. Please try again in 482ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196182, Requested 4096. Please try again in 83ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196182, Requested 4096. Please try again in 83ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199028, Requested 4096. Please try again in 937ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199028, Requested 4096. Please try again in 937ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197760, Requested 4096. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197760, Requested 4096. Please try again in 556ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198418, Requested 4096. Please try again in 754ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198418, Requested 4096. Please try again in 754ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198397, Requested 4096. Please try again in 747ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198397, Requested 4096. Please try again in 747ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197346, Requested 4096. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197346, Requested 4096. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198332, Requested 4096. Please try again in 728ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198332, Requested 4096. Please try again in 728ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198248, Requested 4096. Please try again in 703ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198248, Requested 4096. Please try again in 703ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199309, Requested 4096. Please try again in 1.021s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199309, Requested 4096. Please try again in 1.021s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197866, Requested 4096. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197866, Requested 4096. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197774, Requested 4096. Please try again in 561ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197774, Requested 4096. Please try again in 561ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197430, Requested 4096. Please try again in 457ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197430, Requested 4096. Please try again in 457ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199134, Requested 4096. Please try again in 969ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199134, Requested 4096. Please try again in 969ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199088, Requested 4096. Please try again in 955ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199088, Requested 4096. Please try again in 955ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198614, Requested 4096. Please try again in 813ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198614, Requested 4096. Please try again in 813ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196165, Requested 4096. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196165, Requested 4096. Please try again in 78ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198251, Requested 4096. Please try again in 704ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198251, Requested 4096. Please try again in 704ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197526, Requested 4096. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197526, Requested 4096. Please try again in 486ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197255, Requested 4096. Please try again in 405ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197255, Requested 4096. Please try again in 405ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195991, Requested 4096. Please try again in 26ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 195991, Requested 4096. Please try again in 26ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199041, Requested 4096. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199041, Requested 4096. Please try again in 941ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198749, Requested 4096. Please try again in 853ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198749, Requested 4096. Please try again in 853ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197095, Requested 4096. Please try again in 357ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197095, Requested 4096. Please try again in 357ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196065, Requested 4096. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196065, Requested 4096. Please try again in 48ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197110, Requested 4096. Please try again in 361ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 197110, Requested 4096. Please try again in 361ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196425, Requested 4096. Please try again in 156ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196425, Requested 4096. Please try again in 156ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198093, Requested 4096. Please try again in 656ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198093, Requested 4096. Please try again in 656ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199533, Requested 4096. Please try again in 1.088s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 199533, Requested 4096. Please try again in 1.088s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196407, Requested 4096. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 196407, Requested 4096. Please try again in 150ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\base\\base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphrag\\llm\\openai\\openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1339, in create\n    return await self._post(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1815, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1509, in request\n    return await self._request(\n  File \"C:\\Users\\hansung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1610, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198427, Requested 4096. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n", "source": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-pun4wXd9ZlMJyFLODGFX09XF on tokens per min (TPM): Limit 200000, Used 198427, Requested 4096. Please try again in 756ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}", "details": {"input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"}}
